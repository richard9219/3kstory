#!/bin/bash

# å¿«é€Ÿæµ‹è¯•è„šæœ¬
# ç”¨é€”ï¼šæµ‹è¯•æœ¬åœ°æ¨¡å‹æœåŠ¡æ˜¯å¦æ­£å¸¸å·¥ä½œ

echo "================================"
echo "3kstory æ¨¡å‹å¿«é€Ÿæµ‹è¯•"
echo "================================"
echo ""

# æµ‹è¯• vLLM
if curl -s http://localhost:8000/health > /dev/null 2>&1; then
    echo "âœ… vLLM æœåŠ¡è¿è¡Œä¸­"
    echo ""
    echo "ğŸ§ª æµ‹è¯• vLLM API..."
    curl -X POST http://localhost:8000/v1/completions \
        -H "Content-Type: application/json" \
        -d '{
            "model": "qwen2.5-7b",
            "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚",
            "max_tokens": 50,
            "temperature": 0.7
        }' | python3 -m json.tool
    echo ""
    echo "âœ… vLLM æµ‹è¯•å®Œæˆ"
    exit 0
fi

# æµ‹è¯• Ollama
if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "âœ… Ollama æœåŠ¡è¿è¡Œä¸­"
    echo ""
    echo "ğŸ§ª æµ‹è¯• Ollama API..."
    curl http://localhost:11434/api/generate -d '{
        "model": "qwen2.5:7b",
        "prompt": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚",
        "stream": false
    }' | python3 -m json.tool
    echo ""
    echo "âœ… Ollama æµ‹è¯•å®Œæˆ"
    exit 0
fi

echo "âŒ æœªæ£€æµ‹åˆ°è¿è¡Œä¸­çš„æœåŠ¡"
echo ""
echo "è¯·å…ˆå¯åŠ¨æœåŠ¡ï¼š"
echo "  vLLM:   ./deploy-vllm.sh"
echo "  Ollama: ./deploy-ollama.sh"
exit 1
